{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Automaton_1', 'States': ['s0', 's1', 's2', 's3', 's4', 's5'], 'Alphabet': ['a', 'b', 'c'], 'Transitions': {'s0': {'a': 's0', 'b': 's2', 'c': 's5'}, 's1': {'a': 's1', 'b': 's3', 'c': 's0'}, 's2': {'a': 's2', 'b': 's4', 'c': 's1'}, 's3': {'a': 's3', 'b': 's5', 'c': 's2'}, 's4': {'a': 's4', 'b': 's0', 'c': 's3'}, 's5': {'a': 's5', 'b': 's5', 'c': 's5'}}, 'Start State': 's0', 'Accept States': ['s4', 's5']}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def create_non_minimal_diverse_automata(num_automata):\n",
    "    automata_database = []\n",
    "    \n",
    "    for i in range(1, num_automata + 1):\n",
    "        alphabet = ['a', 'b', 'c']\n",
    "        \n",
    "        num_states = 4 + i % 3\n",
    "        states = [f's{j}' for j in range(num_states)]\n",
    "        # Introduce at least one redundant state explicitly\n",
    "        redundant_state = f's{num_states}'\n",
    "        states.append(redundant_state)\n",
    "        \n",
    "        transitions = {}\n",
    "        for state in states:\n",
    "            transitions[state] = {}\n",
    "            if i % 2 == 0:\n",
    "                transitions[state]['a'] = states[(states.index(state) + 1) % len(states)]\n",
    "                transitions[state]['b'] = states[(states.index(state) - 1) % len(states)]\n",
    "                transitions[state]['c'] = state  # Adding self-loop on 'c' (could be redundant)\n",
    "            else:\n",
    "                transitions[state]['a'] = state\n",
    "                transitions[state]['b'] = states[(states.index(state) + 2) % len(states)]\n",
    "                transitions[state]['c'] = states[(states.index(state) - 1) % len(states)]\n",
    "        # Ensuring redundancy in transitions\n",
    "        transitions[redundant_state]['a'] = redundant_state  # Self-loop\n",
    "        transitions[redundant_state]['b'] = redundant_state  # Self-loop\n",
    "        transitions[redundant_state]['c'] = redundant_state  # Self-loop\n",
    "\n",
    "        start_state = 's0'\n",
    "        # Adding redundancy in accept states\n",
    "        accept_states = [states[-2], redundant_state]\n",
    "        \n",
    "        automaton = {\n",
    "            'Name': f'Automaton_{i}',\n",
    "            'States': states,\n",
    "            'Alphabet': alphabet,\n",
    "            'Transitions': transitions,\n",
    "            'Start State': start_state,\n",
    "            'Accept States': accept_states\n",
    "        }\n",
    "        \n",
    "        automata_database.append(automaton)\n",
    "    \n",
    "    return automata_database\n",
    "\n",
    "# Generate 10 non-minimal diverse automata\n",
    "automata_list = create_non_minimal_diverse_automata(10)\n",
    "\n",
    "# Display the structure of the first automaton for verification\n",
    "print(automata_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Automaton_1',\n",
       " 'States': ['s0', 's1', 's2', 's3', 's4', 's5'],\n",
       " 'Alphabet': ['a', 'b', 'c'],\n",
       " 'Transitions': {'s0': {'a': 's0', 'b': 's2', 'c': 's5'},\n",
       "  's1': {'a': 's1', 'b': 's3', 'c': 's0'},\n",
       "  's2': {'a': 's2', 'b': 's4', 'c': 's1'},\n",
       "  's3': {'a': 's3', 'b': 's5', 'c': 's2'},\n",
       "  's4': {'a': 's4', 'b': 's0', 'c': 's3'},\n",
       "  's5': {'a': 's5', 'b': 's5', 'c': 's5'}},\n",
       " 'Start State': 's0',\n",
       " 'Accept States': ['s4', 's5']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automata_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<structure type=\"fa\" id=\"1\"><automaton name=\"Automaton_1\"><state id=\"0\" name=\"s0\"><x>363</x><y>398</y><initial /></state><state id=\"1\" name=\"s1\"><x>304</x><y>116</y></state><state id=\"2\" name=\"s2\"><x>261</x><y>238</y></state><state id=\"3\" name=\"s3\"><x>397</x><y>157</y></state><state id=\"4\" name=\"s4\"><x>326</x><y>170</y><final /></state><state id=\"5\" name=\"s5\"><x>395</x><y>394</y><final /></state><transition><from>0</from><to>0</to><read>a</read></transition><transition><from>0</from><to>2</to><read>b</read></transition><transition><from>0</from><to>5</to><read>c</read></transition><transition><from>1</from><to>1</to><read>a</read></transition><transition><from>1</from><to>3</to><read>b</read></transition><transition><from>1</from><to>0</to><read>c</read></transition><transition><from>2</from><to>2</to><read>a</read></transition><transition><from>2</from><to>4</to><read>b</read></transition><transition><from>2</from><to>1</to><read>c</read></transition><transition><from>3</from><to>3</to><read>a</read></transition><transition><from>3</from><to>5</to><read>b</read></transition><transition><from>3</from><to>2</to><read>c</read></transition><transition><from>4</from><to>4</to><read>a</read></transition><transition><from>4</from><to>0</to><read>b</read></transition><transition><from>4</from><to>3</to><read>c</read></transition><transition><from>5</from><to>5</to><read>a</read></transition><transition><from>5</from><to>5</to><read>b</read></transition><transition><from>5</from><to>5</to><read>c</read></transition></automaton></structure>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "\n",
    "def create_xml_string(automata_list):\n",
    "    root = ET.Element(\"structure\")\n",
    "    root.set(\"type\", \"fa\")\n",
    "    root.set(\"id\", \"1\")\n",
    "\n",
    "    for automaton in automata_list:\n",
    "        automaton_tag = ET.SubElement(root, \"automaton\")\n",
    "        automaton_tag.set(\"name\", automaton['Name'])\n",
    "        \n",
    "        # Adding states\n",
    "        for i, state in enumerate(automaton['States']):\n",
    "            state_tag = ET.SubElement(automaton_tag, \"state\")\n",
    "            state_tag.set(\"id\", str(i))\n",
    "            state_tag.set(\"name\", state)\n",
    "            x, y = random.randint(100, 400), random.randint(100, 400)  # Random coordinates\n",
    "            ET.SubElement(state_tag, \"x\").text = str(x)\n",
    "            ET.SubElement(state_tag, \"y\").text = str(y)\n",
    "            if state in automaton['Accept States']:\n",
    "                ET.SubElement(state_tag, \"final\")\n",
    "            if state == automaton['Start State']:\n",
    "                ET.SubElement(state_tag, \"initial\")\n",
    "        \n",
    "        # Adding transitions\n",
    "        state_id_map = {state: i for i, state in enumerate(automaton['States'])}\n",
    "        for state, transitions in automaton['Transitions'].items():\n",
    "            for input_symbol, target_state in transitions.items():\n",
    "                transition_tag = ET.SubElement(automaton_tag, \"transition\")\n",
    "                ET.SubElement(transition_tag, \"from\").text = str(state_id_map[state])\n",
    "                ET.SubElement(transition_tag, \"to\").text = str(state_id_map[target_state])\n",
    "                ET.SubElement(transition_tag, \"read\").text = input_symbol\n",
    "\n",
    "    # Convert to ElementTree\n",
    "    tree = ET.ElementTree(root)\n",
    "    # Generate the XML string\n",
    "    import io\n",
    "    xml_string_io = io.StringIO()\n",
    "    tree.write(xml_string_io, encoding='unicode')\n",
    "    return xml_string_io.getvalue()\n",
    "\n",
    "# Generate XML string for the automata\n",
    "xml_content = create_xml_string(automata_list[:1])\n",
    "xml_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML content has been saved to automaton.jff\n"
     ]
    }
   ],
   "source": [
    "def save_xml_to_file(xml_content, file_name):\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(xml_content)\n",
    "\n",
    "# Assuming 'xml_content' is the XML string you want to save\n",
    "file_name = \"automaton.jff\"\n",
    "save_xml_to_file(xml_content, file_name)\n",
    "\n",
    "print(f\"XML content has been saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automaton_1.jff\n",
      "Automaton_2.jff\n",
      "Automaton_3.jff\n",
      "Automaton_4.jff\n",
      "Automaton_5.jff\n",
      "Automaton_6.jff\n",
      "Automaton_7.jff\n",
      "Automaton_8.jff\n",
      "Automaton_9.jff\n",
      "Automaton_10.jff\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "\n",
    "def prettify(element, indent='  '):\n",
    "    queue = [(0, element)]  # (level, element)\n",
    "    while queue:\n",
    "        level, element = queue.pop(0)\n",
    "        children = [(level + 1, child) for child in list(element)]\n",
    "        if children:\n",
    "            element.text = '\\n' + indent * (level+1)  # for child open\n",
    "        if queue:\n",
    "            element.tail = '\\n' + indent * queue[0][0]  # for sibling open\n",
    "        else:\n",
    "            element.tail = '\\n' + indent * (level-1)  # for parent close\n",
    "        queue[0:0] = children  # prepend so children come before siblings\n",
    "\n",
    "def save_automata_to_files(automata_list):\n",
    "    file_paths = []\n",
    "    #base_path = '/path/to/save/location/'  # Specify your local path here\n",
    "\n",
    "    for automaton in automata_list:\n",
    "        root = ET.Element(\"structure\")\n",
    "        #root.set(\"type\", \"fa\")\n",
    "        #root.set(\"id\", \"1\")\n",
    "        comment = ET.Comment('Created with JFLAP 6.4.')\n",
    "        root.append(comment)\n",
    "        type_tag = ET.SubElement(root, \"type\")\n",
    "        type_tag.text = \"fa\"\n",
    "        automaton_tag = ET.SubElement(root, \"automaton\")\n",
    "        \n",
    "        # Adding states\n",
    "        for i, state in enumerate(automaton['States']):\n",
    "            state_tag = ET.SubElement(automaton_tag, \"state\")\n",
    "            state_tag.set(\"id\", str(i))\n",
    "            state_tag.set(\"name\", state)\n",
    "            x, y = random.randint(100, 400), random.randint(100, 400)  # Random coordinates\n",
    "            ET.SubElement(state_tag, \"x\").text = str(x)\n",
    "            ET.SubElement(state_tag, \"y\").text = str(y)\n",
    "            if state in automaton['Accept States']:\n",
    "                ET.SubElement(state_tag, \"final\")\n",
    "            if state == automaton['Start State']:\n",
    "                ET.SubElement(state_tag, \"initial\")\n",
    "        \n",
    "        # Adding transitions\n",
    "        state_id_map = {state: i for i, state in enumerate(automaton['States'])}\n",
    "        for state, transitions in automaton['Transitions'].items():\n",
    "            for input_symbol, target_state in transitions.items():\n",
    "                transition_tag = ET.SubElement(automaton_tag, \"transition\")\n",
    "                ET.SubElement(transition_tag, \"from\").text = str(state_id_map[state])\n",
    "                ET.SubElement(transition_tag, \"to\").text = str(state_id_map[target_state])\n",
    "                ET.SubElement(transition_tag, \"read\").text = input_symbol\n",
    "\n",
    "        # Convert to ElementTree and write to XML\n",
    "        prettify(root)\n",
    "\n",
    "        tree = ET.ElementTree(root)\n",
    "        file_name = f\"{automaton['Name']}.jff\"\n",
    "        file_path = f\"{file_name}\"\n",
    "        #tree.write(file_path)\n",
    "        #file_paths.append(file_path)\n",
    "        with open(file_path, \"w\", encoding=\"UTF-8\") as file:\n",
    "            file.write('<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\\n')\n",
    "            tree.write(file, encoding=\"unicode\")\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "# Assuming 'automata_list' is already defined and contains your automata data\n",
    "file_paths = save_automata_to_files(automata_list)\n",
    "for path in file_paths:\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Automaton',\n",
       " 'States': ['s0', 's1', 's2', 's3', 's4', 's5'],\n",
       " 'Alphabet': ['a', 'b', 'c'],\n",
       " 'Transitions': {'s0': {'a': 's0', 'b': 's2', 'c': 's5'},\n",
       "  's1': {'a': 's1', 'b': 's3', 'c': 's0'},\n",
       "  's2': {'a': 's2', 'b': 's4', 'c': 's1'},\n",
       "  's3': {'a': 's3', 'b': 's5', 'c': 's2'},\n",
       "  's4': {'a': 's4', 'b': 's0', 'c': 's3'},\n",
       "  's5': {'a': 's5', 'b': 's5', 'c': 's5'}},\n",
       " 'Start State': 's0',\n",
       " 'Accept States': ['s4', 's5']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_jff_to_dict(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    automaton_dict = {\n",
    "        'Name': 'Automaton',  # Default name, update if needed\n",
    "        'States': [],\n",
    "        'Alphabet': set(),  # To collect unique symbols\n",
    "        'Transitions': {},\n",
    "        'Start State': None,\n",
    "        'Accept States': []\n",
    "    }\n",
    "\n",
    "    # Extract states and organize transitions\n",
    "    for state in root.findall('.//state'):\n",
    "        state_id = state.get('id')\n",
    "        state_name = state.get('name') if state.get('name') else state_id\n",
    "        automaton_dict['States'].append(state_name)\n",
    "        automaton_dict['Transitions'][state_name] = {}\n",
    "\n",
    "        # Check for initial and final tags\n",
    "        if state.find('initial') is not None:\n",
    "            automaton_dict['Start State'] = state_name\n",
    "        if state.find('final') is not None:\n",
    "            automaton_dict['Accept States'].append(state_name)\n",
    "\n",
    "    # Extract transitions and form the transition dictionary properly\n",
    "    for transition in root.findall('.//transition'):\n",
    "        from_state = root.find(f\".//state[@id='{transition.find('from').text}']\").get('name')\n",
    "        to_state = root.find(f\".//state[@id='{transition.find('to').text}']\").get('name')\n",
    "        read_symbol = transition.find('read').text if transition.find('read') is not None else ''\n",
    "        automaton_dict['Alphabet'].add(read_symbol)\n",
    "        if read_symbol not in automaton_dict['Transitions'][from_state]:\n",
    "            automaton_dict['Transitions'][from_state][read_symbol] = to_state\n",
    "        else:\n",
    "            # Handle non-deterministic cases by choosing one transition\n",
    "            automaton_dict['Transitions'][from_state][read_symbol] = to_state\n",
    "\n",
    "    # Convert Alphabet set to sorted list\n",
    "    automaton_dict['Alphabet'] = sorted(automaton_dict['Alphabet'])\n",
    "\n",
    "    return automaton_dict\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'Automaton_1.jff'\n",
    "automaton = parse_jff_to_dict(file_path)\n",
    "automaton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'States': ['s0', 's1', 's2', 's3', 's4', 's5'],\n",
       " 'Alphabet': ['a', 'b', 'c'],\n",
       " 'Transitions': {'s0': {'a': 's4', 'b': 's0', 'c': 's3'},\n",
       "  's1': {'a': 's5', 'b': 's5', 'c': 's5'},\n",
       "  's2': {'a': 's1', 'b': 's3', 'c': 's0'},\n",
       "  's3': {'a': 's3', 'b': 's5', 'c': 's2'},\n",
       "  's4': {'a': 's2', 'b': 's4', 'c': 's1'},\n",
       "  's5': {'a': 's0', 'b': 's2', 'c': 's5'}},\n",
       " 'Start State': 's0',\n",
       " 'Accept States': ['s0', 's1']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AutomatonMinimization:\n",
    "    def __init__(self, automaton):\n",
    "        self.states = {state: {'is_final': state in automaton['Accept States'], 'transitions': automaton['Transitions'][state]} for state in automaton['States']}\n",
    "        self.start_state = automaton['Start State']\n",
    "        self.alphabet = automaton['Alphabet']\n",
    "\n",
    "    def minimize(self):\n",
    "        partition = self.initial_partition()\n",
    "        \n",
    "        changed = True\n",
    "        while changed:\n",
    "            new_partition = []\n",
    "            changed = False\n",
    "            \n",
    "            for group in partition:\n",
    "                new_groups = {}\n",
    "                for state in group:\n",
    "                    state_transitions = {symbol: tuple(self.find_group(self.states[state]['transitions'].get(symbol, None), partition)) for symbol in self.alphabet}\n",
    "                    group_key = tuple(sorted((symbol, trans) for symbol, trans in state_transitions.items()))\n",
    "                    if group_key not in new_groups:\n",
    "                        new_groups[group_key] = []\n",
    "                    new_groups[group_key].append(state)\n",
    "                \n",
    "                if len(new_groups) > 1:\n",
    "                    changed = True\n",
    "                \n",
    "                new_partition.extend(new_groups.values())\n",
    "\n",
    "            partition = new_partition\n",
    "\n",
    "        new_states = []\n",
    "        for group in partition:\n",
    "            is_final = any(self.states[state]['is_final'] for state in group)\n",
    "            transitions = {}\n",
    "            sample_state = group[0]\n",
    "            for symbol in self.alphabet:\n",
    "                target = self.states[sample_state]['transitions'].get(symbol)\n",
    "                if target is not None:\n",
    "                    transitions[symbol] = self.find_group(target, partition)[0]\n",
    "            new_states.append({'is_final': is_final, 'transitions': transitions})\n",
    "\n",
    "        # Reconstructing the minimized automaton\n",
    "        return {\n",
    "            'States': ['s{}'.format(i) for i in range(len(new_states))],\n",
    "            'Alphabet': self.alphabet,\n",
    "            'Transitions': {f's{i}': new_states[i]['transitions'] for i in range(len(new_states))},\n",
    "            'Start State': 's0',\n",
    "            'Accept States': ['s{}'.format(i) for i, state in enumerate(new_states) if state['is_final']]\n",
    "        }\n",
    "\n",
    "    def initial_partition(self):\n",
    "        finais = {state for state in self.states if self.states[state]['is_final']}\n",
    "        nao_finais = set(self.states) - finais\n",
    "        return [finais, nao_finais] if finais and nao_finais else [finais]\n",
    "\n",
    "    def find_group(self, state, partition):\n",
    "        for group in partition:\n",
    "            if state in group:\n",
    "                return group\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "automaton = {\n",
    "    'Name': 'Automaton',\n",
    "    'States': ['s0', 's1', 's2', 's3', 's4', 's5'],\n",
    "    'Alphabet': ['a', 'b', 'c'],\n",
    "    'Transitions': {\n",
    "        's0': {'a': 's0', 'b': 's2', 'c': 's5'},\n",
    "        's1': {'a': 's1', 'b': 's3', 'c': 's0'},\n",
    "        's2': {'a': 's2', 'b': 's4', 'c': 's1'},\n",
    "        's3': {'a': 's3', 'b': 's5', 'c': 's2'},\n",
    "        's4': {'a': 's4', 'b': 's0', 'c': 's3'},\n",
    "        's5': {'a': 's5', 'b': 's5', 'c': 's5'}\n",
    "    },\n",
    "    'Start State': 's0',\n",
    "    'Accept States': ['s4', 's5']\n",
    "}\n",
    "\n",
    "minimizer = AutomatonMinimization(automaton)\n",
    "minimized_automaton = minimizer.minimize()\n",
    "minimized_automaton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'States': ['q0', 'q1'],\n",
       " 'Alphabet': ['a', 'b'],\n",
       " 'Transitions': {'q0': {'a': 'q1', 'b': 'q0'}, 'q1': {'a': 'q1', 'b': 'q0'}},\n",
       " 'Start State': 'q1',\n",
       " 'Accept States': ['q0']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minimize_dfa(automaton):\n",
    "    states = set(automaton['States'])\n",
    "    alphabet = automaton['Alphabet']\n",
    "    transitions = automaton['Transitions']\n",
    "    start_state = automaton['Start State']\n",
    "    accept_states = set(automaton['Accept States'])\n",
    "\n",
    "    # Initial partition\n",
    "    P = [accept_states, states - accept_states]\n",
    "    work_list = list(P)  # To keep track of partitions to refine\n",
    "\n",
    "    # Refinement step\n",
    "    while work_list:\n",
    "        A = work_list.pop()\n",
    "        for c in alphabet:\n",
    "            X = set(s for s in states if transitions.get(s, {}).get(c) in A)\n",
    "            new_partitions = []\n",
    "            for Y in P:\n",
    "                intersect = Y & X\n",
    "                difference = Y - X\n",
    "                if intersect and difference:\n",
    "                    new_partitions.extend([intersect, difference])\n",
    "                    if Y in work_list:\n",
    "                        work_list.extend([intersect, difference])\n",
    "                    else:\n",
    "                        # Add the smaller partition to reduce future work\n",
    "                        work_list.append(intersect if len(intersect) <= len(difference) else difference)\n",
    "                else:\n",
    "                    new_partitions.append(Y)\n",
    "            P = new_partitions\n",
    "\n",
    "    # Reconstructing the minimized DFA\n",
    "    state_mapping = {}\n",
    "    new_states = []\n",
    "    new_transitions = {}\n",
    "    new_start_state = None\n",
    "    new_accept_states = []\n",
    "\n",
    "    # Create new state names and find the new start and accept states\n",
    "    for index, part in enumerate(P):\n",
    "        new_state_name = f\"q{index}\"\n",
    "        new_states.append(new_state_name)\n",
    "        state_mapping.update({s: new_state_name for s in part})\n",
    "        if start_state in part:\n",
    "            new_start_state = new_state_name\n",
    "        if part & accept_states:\n",
    "            new_accept_states.append(new_state_name)\n",
    "\n",
    "    # Reconstructing transitions for the new states\n",
    "    for part in P:\n",
    "        representative = next(iter(part))  # Any state from the partition\n",
    "        new_state_name = state_mapping[representative]\n",
    "        for a in alphabet:\n",
    "            target_state = transitions[representative].get(a)\n",
    "            if target_state:\n",
    "                new_transitions.setdefault(new_state_name, {})[a] = state_mapping[target_state]\n",
    "\n",
    "    # The minimized automaton in the same format\n",
    "    minimized_automaton = {\n",
    "        'States': new_states,\n",
    "        'Alphabet': alphabet,\n",
    "        'Transitions': new_transitions,\n",
    "        'Start State': new_start_state,\n",
    "        'Accept States': new_accept_states\n",
    "    }\n",
    "\n",
    "    return minimized_automaton\n",
    "\n",
    "# Example DFA\n",
    "# dfa = {\n",
    "#     'States': ['s0', 's1', 's2', 's3', 's4', 's5'],\n",
    "#     'Alphabet': ['a', 'b', 'c'],\n",
    "#     'Transitions': {\n",
    "#         's0': {'a': 's4', 'b': 's0', 'c': 's3'},\n",
    "#         's1': {'a': 's5', 'b': 's5', 'c': 's5'},\n",
    "#         's2': {'a': 's1', 'b': 's3', 'c': 's0'},\n",
    "#         's3': {'a': 's3', 'b': 's5', 'c': 's2'},\n",
    "#         's4': {'a': 's2', 'b': 's4', 'c': 's1'},\n",
    "#         's5': {'a': 's0', 'b': 's2', 'c': 's5'}\n",
    "#     },\n",
    "#     'Start State': 's0',\n",
    "#     'Accept States': ['s0', 's1']\n",
    "# }\n",
    "non_minimal_dfa = {\n",
    "    'States': ['s0', 's1', 's2', 's3'],  # More states than necessary\n",
    "    'Alphabet': ['a', 'b'],\n",
    "    'Transitions': {\n",
    "        's0': {'a': 's1', 'b': 's2'},\n",
    "        's1': {'a': 's1', 'b': 's1'},  # States s1 and s3 can be merged\n",
    "        's2': {'a': 's1', 'b': 's2'},\n",
    "        's3': {'a': 's1', 'b': 's1'},  # Redundant state, behaves like s1\n",
    "    },\n",
    "    'Start State': 's0',\n",
    "    'Accept States': ['s1']\n",
    "}\n",
    "non_minimal_dfa2 = {\n",
    "    'States': ['s0', 's1', 's2', 's3'],  # Extra state s3 that is not necessary\n",
    "    'Alphabet': ['a', 'b'],\n",
    "    'Transitions': {\n",
    "        's0': {'a': 's1', 'b': 's0'},\n",
    "        's1': {'a': 's0', 'b': 's1'},\n",
    "        's2': {'a': 's3', 'b': 's2'},  # s2 is an unnecessary duplicate of s0\n",
    "        's3': {'a': 's2', 'b': 's3'},  # s3 is an unnecessary duplicate of s1\n",
    "    },\n",
    "    'Start State': 's0',\n",
    "    'Accept States': ['s0']\n",
    "} #deu ruim esse aqui\n",
    "non_minimal_dfa3 = {\n",
    "    'States': ['s0', 's1', 's2', 's3', 's4'],  # Extra states s3 and s4\n",
    "    'Alphabet': ['a', 'b'],\n",
    "    'Transitions': {\n",
    "        's0': {'a': 's1', 'b': 's2'},\n",
    "        's1': {'a': 's1', 'b': 's2'},\n",
    "        's2': {'a': 's1', 'b': 's2'},\n",
    "        's3': {'a': 's1', 'b': 's2'},  # s3 is redundant, behaves like s1\n",
    "        's4': {'a': 's1', 'b': 's2'},  # s4 is redundant, behaves like s2\n",
    "    },\n",
    "    'Start State': 's0',\n",
    "    'Accept States': ['s2']\n",
    "}\n",
    "\n",
    "minimized_dfa = minimize_dfa(non_minimal_dfa3)\n",
    "minimized_dfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'States': ['q0', 'q1'],\n",
       " 'Alphabet': ['a', 'b'],\n",
       " 'Transitions': {'q1': {'a': 'q1', 'b': 'q0'}, 'q0': {'a': 'q1', 'b': 'q0'}},\n",
       " 'Start State': 'q1',\n",
       " 'Accept States': ['q0']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minimize_dfa(automaton):\n",
    "    states = set(automaton['States'])\n",
    "    alphabet = automaton['Alphabet']\n",
    "    transitions = automaton['Transitions']\n",
    "    start_state = automaton['Start State']\n",
    "    accept_states = set(automaton['Accept States'])\n",
    "\n",
    "    # Initial partition\n",
    "    P = [accept_states, states - accept_states]\n",
    "    t = len(P)  # Counter for partitions\n",
    "    W = list(P)  # Working list to process partitions\n",
    "\n",
    "    # Refinement step\n",
    "    while W:\n",
    "        A = W.pop(0)\n",
    "        for a in alphabet:\n",
    "            for i in range(len(P)):\n",
    "                Qi = P[i]\n",
    "                affected_states = {q for q in Qi if transitions.get(q, {}).get(a) in A}\n",
    "                if not affected_states:\n",
    "                    continue  # No states affected by this transition, skip to next\n",
    "\n",
    "                # Compare all possible partitions\n",
    "                for j1 in range(t):\n",
    "                    for j2 in range(j1 + 1, t):\n",
    "                        Qj1 = P[j1]\n",
    "                        Qj2 = P[j2]\n",
    "                        S1 = {q for q in Qi if transitions.get(q, {}).get(a) in Qj1}\n",
    "                        S2 = {q for q in Qi if transitions.get(q, {}).get(a) in Qj2}\n",
    "\n",
    "                        if S1 and S2:\n",
    "                            if len(S1) <= len(S2):\n",
    "                                new_partition = S1\n",
    "                            else:\n",
    "                                new_partition = S2\n",
    "\n",
    "                            # Update Qi and add new partition\n",
    "                            Qi_difference = Qi - new_partition\n",
    "                            if Qi_difference:\n",
    "                                P.append(Qi_difference)\n",
    "                                if Qi in W:\n",
    "                                    W.append(Qi_difference)\n",
    "                                Qi.clear()\n",
    "                                Qi.update(new_partition)\n",
    "                                if new_partition not in W:\n",
    "                                    W.append(new_partition)\n",
    "                            t += 1  # Increment partition count\n",
    "\n",
    "    # Construct minimized DFA\n",
    "    state_mapping = {q: f\"q{P.index(part)}\" for part in P for q in part}\n",
    "    new_states = [f\"q{index}\" for index, _ in enumerate(P)]\n",
    "    new_transitions = {}\n",
    "    new_start_state = state_mapping[start_state]\n",
    "    new_accept_states = [state_mapping[q] for q in accept_states if q in state_mapping]\n",
    "\n",
    "    # Reconstruct transitions for new states\n",
    "    for q in states:\n",
    "        original_state = state_mapping[q]\n",
    "        new_transitions.setdefault(original_state, {})\n",
    "        for a in alphabet:\n",
    "            target_state = transitions[q].get(a)\n",
    "            if target_state in state_mapping:\n",
    "                new_transitions[original_state][a] = state_mapping[target_state]\n",
    "\n",
    "    # Construct the output DFA\n",
    "    minimized_dfa = {\n",
    "        'States': new_states,\n",
    "        'Alphabet': alphabet,\n",
    "        'Transitions': new_transitions,\n",
    "        'Start State': new_start_state,\n",
    "        'Accept States': new_accept_states\n",
    "    }\n",
    "\n",
    "    return minimized_dfa\n",
    "\n",
    "# Define a sample DFA to minimize\n",
    "sample_dfa = {\n",
    "    'States': ['s0', 's1', 's2', 's3'],\n",
    "    'Alphabet': ['a', 'b'],\n",
    "    'Transitions': {\n",
    "        's0': {'a': 's1', 'b': 's2'},\n",
    "        's1': {'a': 's2', 'b': 's3'},\n",
    "        's2': {'a': 's3', 'b': 's0'},\n",
    "        's3': {'a': 's0', 'b': 's1'}\n",
    "    },\n",
    "    'Start State': 's0',\n",
    "    'Accept States': ['s3']\n",
    "}\n",
    "\n",
    "minimized_dfa = minimize_dfa(non_minimal_dfa3)\n",
    "minimized_dfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
